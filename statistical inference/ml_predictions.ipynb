{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt # to better format confusion matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_deaths_clean.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Value Percentages by Column: \n",
      "\n",
      "                       count     %\n",
      "id                         1   0.0\n",
      "state                      0   0.0\n",
      "county                     0   0.0\n",
      "jail                       0   0.0\n",
      "year                       0   0.0\n",
      "date_of_death            282   3.7\n",
      "gender                   389   5.1\n",
      "cause_short              576   7.6\n",
      "race                     672   8.9\n",
      "custody_status          1251  16.5\n",
      "first_name              1361  18.0\n",
      "last_name               1361  18.0\n",
      "cause_detail            1474  19.5\n",
      "cause_detail_group      1474  19.5\n",
      "date_incarcerated       1909  25.2\n",
      "length_incarceration    1913  25.3\n",
      "dob                     3915  51.7\n",
      "age                     4246  56.1\n",
      "mid_name                5775  76.3\n",
      "full_name               6293  83.1\n",
      "what_info_from_media    7253  95.8\n",
      "num_media_descriptors   7253  95.8\n",
      "yob                     7355  97.1\n",
      "suffix                  7504  99.1\n",
      "race_detail             7535  99.5\n"
     ]
    }
   ],
   "source": [
    "nan_counts = df.isna().sum()\n",
    "percentages = round(df.isna().mean() * 100, 1)\n",
    "null_values = pd.concat([nan_counts, percentages], axis=1, keys=[\"count\", \"%\"])\n",
    "\n",
    "print(\"NaN Value Percentages by Column: \\n\")\n",
    "print(null_values.sort_values(by=[\"%\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271\n",
      "5300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 924 features, but LogisticRegression is expecting 824 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [79], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m# print(len(test_categorical))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# print(len(test_numerical))\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(predict_input))\n\u001b[0;32m---> 35\u001b[0m predict_output \u001b[39m=\u001b[39m logistic_model\u001b[39m.\u001b[39;49mpredict(predict_input)\n\u001b[1;32m     38\u001b[0m ConfusionMatrixDisplay\u001b[39m.\u001b[39mfrom_estimator(logistic_model, predict_input, test_target)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    449\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_base.py:429\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    430\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    431\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 924 features, but LogisticRegression is expecting 824 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "# df_model_data = df[[\"id\", \"year\",\"yob\",\"age\",\"gender\",\"num_media_descriptors\",\"length_incarceration\",\"cause_detail_group\"]]\n",
    "df_model_data = df[[\"id\", \"state\", \"county\", \"jail\", \"year\", \"gender\", \"cause_short\", \"race\", \"cause_detail_group\", \"length_incarceration\"]]\n",
    "df_model_data_remove_nans = df_model_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "data = df_model_data_remove_nans.drop(columns=[\"gender\"])\n",
    "target = df_model_data_remove_nans[\"gender\"]\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    data, target, test_size=0.7, random_state=999)\n",
    "\n",
    "train_categorical = OneHotEncoder().fit_transform(train_data[[\"state\",\"county\", \"jail\", \"cause_short\", \"race\", \"cause_detail_group\"]].values).toarray()\n",
    "train_numerical = train_data.drop(columns = [\"state\",\"county\", \"jail\", \"cause_short\", \"race\", \"cause_detail_group\"], axis = 1).values\n",
    "\n",
    "# combining numerical and categorical data\n",
    "joined_data = np.append(train_categorical, train_numerical, axis=1)\n",
    "# print(len(test_data))\n",
    "# print(len(train_data))\n",
    "# print(len(train_target))\n",
    "print(len(joined_data))\n",
    "\n",
    "test_categorical = OneHotEncoder().fit_transform(test_data[[\"state\", \"county\", \"jail\", \"cause_short\", \"race\", \"cause_detail_group\"]].values).toarray()\n",
    "test_numerical = test_data.drop(columns = [\"state\", \"county\", \"jail\", \"cause_short\", \"race\", \"cause_detail_group\"], axis = 1).values\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter = 1000)\n",
    "logistic_model.fit(X = joined_data, y = train_target)\n",
    "\n",
    "# print(len(joined_data))\n",
    "# print(len(train_target))\n",
    "\n",
    "predict_input = np.append(test_categorical, test_numerical, axis=1)\n",
    "# print(len(test_categorical))\n",
    "# print(len(test_numerical))\n",
    "print(len(predict_input))\n",
    "\n",
    "predict_output = logistic_model.predict(predict_input)\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(logistic_model, predict_input, test_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
